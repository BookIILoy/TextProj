{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ntscraper import Nitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances: 100%|██████████| 77/77 [02:15<00:00,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "Scraper = Nitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22-Apr-24 13:14:55 - No instance specified, using random instance https://nitter.esmailelbob.xyz\n",
      "22-Apr-24 13:15:02 - Current stats for realDonaldTrump: 20 tweets, 0 threads...\n",
      "22-Apr-24 13:15:07 - Current stats for realDonaldTrump: 40 tweets, 0 threads...\n",
      "22-Apr-24 13:15:11 - Current stats for realDonaldTrump: 60 tweets, 0 threads...\n",
      "22-Apr-24 13:15:15 - Current stats for realDonaldTrump: 79 tweets, 0 threads...\n",
      "22-Apr-24 13:15:19 - Current stats for realDonaldTrump: 98 tweets, 0 threads...\n",
      "22-Apr-24 13:15:23 - Current stats for realDonaldTrump: 100 tweets, 0 threads...\n"
     ]
    }
   ],
   "source": [
    "#tweets =Scraper.get_tweets(\"realDonaldTrump\",mode ='user',number = 100)\n",
    "def scraping(input):\n",
    "    tweets =Scraper.get_tweets(input,mode ='user',number = 100)\n",
    "    return tweets\n",
    "\n",
    "tweets = scraping(\"realDonaldTrump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tweets = []\n",
    "for tweet in tweets['tweets']:\n",
    "    #data = [tweet['link'],tweet['text'],tweet['date'],tweet['stats']['likes'],tweet['stats']['comments']]\n",
    "    data = [tweet['text']]\n",
    "    final_tweets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DONALDJTRUMP.COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To all of those who have asked, I will not be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The 75,000,000 great American Patriots who vot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am asking for everyone at the U.S. Capitol t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NEW: A growing number of Republican senators —...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Today, I am joining a group of Senators to pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>https://secure.winred.com/save-america/electio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Glad to see more Senators joining the fight on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>So true. Thanks Josh!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0                                    DONALDJTRUMP.COM\n",
       "1   To all of those who have asked, I will not be ...\n",
       "2   The 75,000,000 great American Patriots who vot...\n",
       "3                                                    \n",
       "4   I am asking for everyone at the U.S. Capitol t...\n",
       "..                                                ...\n",
       "95  NEW: A growing number of Republican senators —...\n",
       "96  Today, I am joining a group of Senators to pro...\n",
       "97  https://secure.winred.com/save-america/electio...\n",
       "98  Glad to see more Senators joining the fight on...\n",
       "99                              So true. Thanks Josh!\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =pd.DataFrame(final_tweets, columns= ['text'])\n",
    "data\n",
    "#columns= ['link','text','date','no_likes','comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\bookz\\AppData\\Local\\Temp\\ipykernel_5712\\1992885417.py:12: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
      "C:\\Users\\bookz\\AppData\\Local\\Temp\\ipykernel_5712\\1992885417.py:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  text = re.sub('\\w\\d\\w', '', text)\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "def clean(text):\n",
    "    import re\n",
    "    import nltk\n",
    "    from nltk.util import pr\n",
    "    stemmer = nltk.SnowballStemmer(\"english\")\n",
    "    from nltk.corpus import stopwords\n",
    "    import string\n",
    "    stopword = set(stopwords.words(\"english\"))\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('[.?]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w\\d\\w', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text = \" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "with open('clean_function.pkl', 'wb') as f:\n",
    "     dill.dump(clean, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model = pickle.load(open(\"model.pkl\",\"rb\"))\n",
    "cv = pickle.load(open(\"vectorizer.pkl\",\"rb\"))\n",
    "\n",
    "def predict(input):\n",
    "    input = cv.transform([input]).toarray()\n",
    "    predict = model.predict(input)[0]\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score about Negative and Nuetral in This user is\n",
      " Negative =  14 \n",
      " Nuetral =  66\n"
     ]
    }
   ],
   "source": [
    "tweets_cleaned = []\n",
    "Negative = 0\n",
    "Nuetral = 0\n",
    "for i in range(len(final_tweets)):\n",
    "    clean_tweets = clean(final_tweets[i])\n",
    "    if clean_tweets != \"\":\n",
    "        tweets_cleaned.append(clean_tweets)\n",
    "\n",
    "\n",
    "for i in range(len(tweets_cleaned)):\n",
    "    prediction = predict(tweets_cleaned[i])\n",
    "    if prediction == \"No hate and offensive speech\":\n",
    "        Nuetral += 1\n",
    "    elif prediction == \"Offensive language detected\":\n",
    "        Negative += 1\n",
    "    else :\n",
    "       Negative += 1\n",
    "\n",
    "print(\"Score about Negative and Nuetral in This user is\\n Negative = \" , Negative , \"\\n Nuetral = \" , Nuetral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to run backend don't forget to run this part.\n",
    "# import dill\n",
    "# def Scrapr(input):\n",
    "#     import re\n",
    "#     import os\n",
    "#     import nltk\n",
    "#     from nltk.util import pr\n",
    "#     from ntscraper import Nitter\n",
    "#     import pickle\n",
    "#     base_dir = \"textback\"\n",
    "#     models_folder = \"models\"\n",
    "#     model_path = \"model.pkl\"\n",
    "#     vectorizer_path = \"vectorizer.pkl\"\n",
    "\n",
    "#     model_join = os.path.join(base_dir, models_folder, model_path)\n",
    "#     vectorizer_join = os.path.join(base_dir, models_folder, vectorizer_path)\n",
    "#     model = pickle.load(open(model_join, \"rb\"))\n",
    "#     cv = pickle.load(open(vectorizer_join, \"rb\"))\n",
    "#     Scraper = Nitter()\n",
    "#     stemmer = nltk.SnowballStemmer(\"english\")\n",
    "#     from nltk.corpus import stopwords\n",
    "#     import string\n",
    "#     stopword = set(stopwords.words(\"english\"))\n",
    "#     tweets = Scraper.get_tweets(input, mode='user', number=100)\n",
    "#     final_tweets = []\n",
    "#     for tweet in tweets['tweets']:\n",
    "#         data = [tweet['text']]\n",
    "#         final_tweets.append(data)\n",
    "\n",
    "#     def clean(text):\n",
    "#         text = str(text).lower()\n",
    "#         text = re.sub('[.?]', '', text)\n",
    "#         text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "#         text = re.sub('<.?>+', '', text)\n",
    "#         text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "#         text = re.sub('\\n', '', text)\n",
    "#         text = re.sub('\\w\\d\\w', '', text)\n",
    "#         text = [word for word in text.split(' ') if word not in stopword]\n",
    "#         text = \" \".join(text)\n",
    "#         text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "#         text = \" \".join(text)\n",
    "#         return text\n",
    "#     def predict(input):\n",
    "#         input = cv.transform([input]).toarray()\n",
    "#         predict = model.predict(input)[0]\n",
    "#         return predict\n",
    "    \n",
    "#     tweets_cleaned = []\n",
    "#     Negative = 0\n",
    "#     Neutral = 0\n",
    "#     for i in range(len(final_tweets)):\n",
    "#         clean_tweets = clean(final_tweets[i])\n",
    "#         if clean_tweets != \"\":\n",
    "#             tweets_cleaned.append(clean_tweets)\n",
    "\n",
    "#     for i in range(len(tweets_cleaned)):\n",
    "#         prediction = predict(tweets_cleaned[i])\n",
    "#         if prediction == \"No hate and offensive speech\":\n",
    "#             Neutral += 1\n",
    "#         elif prediction == \"Offensive language detected\":\n",
    "#             Negative += 1\n",
    "#         else:\n",
    "#             Negative += 1\n",
    "\n",
    "#     return Negative, Neutral\n",
    "\n",
    "# with open('scraper_function.pkl', 'wb') as f:\n",
    "#     dill.dump(Scrapr, f)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
