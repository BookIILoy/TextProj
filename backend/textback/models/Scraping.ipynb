{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bookz\\AppData\\Local\\Temp\\ipykernel_11824\\3136252630.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ntscraper import Nitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances: 100%|██████████| 77/77 [02:26<00:00,  1.90s/it]\n"
     ]
    }
   ],
   "source": [
    "Scraper = Nitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21-Apr-24 20:45:31 - No instance specified, using random instance https://nitter.esmailelbob.xyz\n",
      "21-Apr-24 20:45:37 - Current stats for realDonaldTrump: 20 tweets, 0 threads...\n",
      "21-Apr-24 20:45:42 - Current stats for realDonaldTrump: 40 tweets, 0 threads...\n",
      "21-Apr-24 20:45:46 - Current stats for realDonaldTrump: 60 tweets, 0 threads...\n",
      "21-Apr-24 20:45:51 - Current stats for realDonaldTrump: 79 tweets, 0 threads...\n",
      "21-Apr-24 20:45:56 - Current stats for realDonaldTrump: 98 tweets, 0 threads...\n",
      "21-Apr-24 20:46:00 - Current stats for realDonaldTrump: 100 tweets, 0 threads...\n"
     ]
    }
   ],
   "source": [
    "#tweets =Scraper.get_tweets(\"realDonaldTrump\",mode ='user',number = 100)\n",
    "def scraping(input):\n",
    "    tweets =Scraper.get_tweets(input,mode ='user',number = 100)\n",
    "    return tweets\n",
    "\n",
    "tweets = scraping(\"realDonaldTrump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tweets = []\n",
    "for tweet in tweets['tweets']:\n",
    "    #data = [tweet['link'],tweet['text'],tweet['date'],tweet['stats']['likes'],tweet['stats']['comments']]\n",
    "    data = [tweet['text']]\n",
    "    final_tweets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DONALDJTRUMP.COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To all of those who have asked, I will not be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The 75,000,000 great American Patriots who vot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am asking for everyone at the U.S. Capitol t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NEW: A growing number of Republican senators —...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Today, I am joining a group of Senators to pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>https://secure.winred.com/save-america/electio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Glad to see more Senators joining the fight on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>So true. Thanks Josh!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0                                    DONALDJTRUMP.COM\n",
       "1   To all of those who have asked, I will not be ...\n",
       "2   The 75,000,000 great American Patriots who vot...\n",
       "3                                                    \n",
       "4   I am asking for everyone at the U.S. Capitol t...\n",
       "..                                                ...\n",
       "95  NEW: A growing number of Republican senators —...\n",
       "96  Today, I am joining a group of Senators to pro...\n",
       "97  https://secure.winred.com/save-america/electio...\n",
       "98  Glad to see more Senators joining the fight on...\n",
       "99                              So true. Thanks Josh!\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =pd.DataFrame(final_tweets, columns= ['text'])\n",
    "data\n",
    "#columns= ['link','text','date','no_likes','comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\bookz\\AppData\\Local\\Temp\\ipykernel_11824\\3496343119.py:12: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
      "C:\\Users\\bookz\\AppData\\Local\\Temp\\ipykernel_11824\\3496343119.py:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  text = re.sub('\\w\\d\\w', '', text)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.util import pr\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopword = set(stopwords.words(\"english\"))\n",
    "\n",
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('[.?]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w\\d\\w', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text = \" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model = pickle.load(open(\"model.pkl\",\"rb\"))\n",
    "cv = pickle.load(open(\"vectorizer.pkl\",\"rb\"))\n",
    "\n",
    "def predict(input):\n",
    "    input = cv.transform([input]).toarray()\n",
    "    predict = model.predict(input)[0]\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "Offensive language detected\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "Offensive language detected\n",
      "No hate and offensive speech\n",
      "Offensive language detected\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "Offensive language detected\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "Offensive language detected\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "Offensive language detected\n",
      "Hate speech Detected\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "Offensive language detected\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "Hate speech Detected\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "Offensive language detected\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "Offensive language detected\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "Hate speech Detected\n",
      "Offensive language detected\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "Offensive language detected\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "No hate and offensive speech\n",
      "Score about Negative and Nuetral in This user is\n",
      " Negative =  14 \n",
      " Nuetral =  66\n"
     ]
    }
   ],
   "source": [
    "tweets_cleaned = []\n",
    "Negative = 0\n",
    "Nuetral = 0\n",
    "for i in range(100):\n",
    "    clean_tweets = clean(final_tweets[i])\n",
    "    if clean_tweets != \"\":\n",
    "        tweets_cleaned.append(clean_tweets)\n",
    "\n",
    "\n",
    "for i in range(len(tweets_cleaned)):\n",
    "    prediction = predict(tweets_cleaned[i])\n",
    "    if prediction == \"No hate and offensive speech\":\n",
    "        Nuetral += 1\n",
    "    elif prediction == \"Offensive language detected\":\n",
    "        Negative += 1\n",
    "    else :\n",
    "       Negative += 1\n",
    "\n",
    "print(\"Score about Negative and Nuetral in This user is\\n Negative = \" , Negative , \"\\n Nuetral = \" , Nuetral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
