{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bookz\\AppData\\Local\\Temp\\ipykernel_9708\\3136252630.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ntscraper import Nitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [01:47<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "Scraper = Nitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-Apr-24 04:15:43 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "24-Apr-24 04:15:49 - Current stats for elonmusk: 20 tweets, 0 threads...\n",
      "24-Apr-24 04:15:53 - Current stats for elonmusk: 40 tweets, 0 threads...\n",
      "24-Apr-24 04:15:56 - Current stats for elonmusk: 60 tweets, 0 threads...\n",
      "24-Apr-24 04:16:00 - Current stats for elonmusk: 80 tweets, 0 threads...\n",
      "24-Apr-24 04:16:04 - Current stats for elonmusk: 100 tweets, 0 threads...\n",
      "24-Apr-24 04:16:08 - Current stats for elonmusk: 120 tweets, 0 threads...\n",
      "24-Apr-24 04:16:11 - Fetching error: Instance has been rate limited.Use another instance or try again later.\n"
     ]
    }
   ],
   "source": [
    "#tweets =Scraper.get_tweets(\"realDonaldTrump\",mode ='user',number = 100)\n",
    "def scraping(input):\n",
    "    tweets =Scraper.get_tweets(input,mode ='user',number = 500)\n",
    "    return tweets\n",
    "\n",
    "tweets = scraping(\"elonmusk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tweets = []\n",
    "for tweet in tweets['tweets']:\n",
    "    #data = [tweet['link'],tweet['text'],tweet['date'],tweet['stats']['likes'],tweet['stats']['comments']]\n",
    "    data = [tweet['text'],tweet['date']]\n",
    "    final_tweets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.DataFrame(final_tweets, columns= ['text','date'])\n",
    "#columns= ['link','text','date','no_likes','comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bookz\\AppData\\Local\\Temp\\ipykernel_9708\\4118179080.py:2: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  data['date'] = data['date'].dt.to_period('M')\n"
     ]
    }
   ],
   "source": [
    "data['date'] = pd.to_datetime(data['date'], format='%b %d, %Y ¬∑ %I:%M %p %Z')\n",
    "data['date'] = data['date'].dt.to_period('M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NPR has become a hard left propaganda machine ...</td>\n",
       "      <td>2024-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>FSD Supervised continues to improve with every...</td>\n",
       "      <td>2024-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Interesting series about a potentially good fu...</td>\n",
       "      <td>2024-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>United States laws prevent ùïè from participatin...</td>\n",
       "      <td>2024-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Interesting</td>\n",
       "      <td>2024-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text     date\n",
       "115  NPR has become a hard left propaganda machine ...  2024-04\n",
       "116  FSD Supervised continues to improve with every...  2024-04\n",
       "117  Interesting series about a potentially good fu...  2024-04\n",
       "118  United States laws prevent ùïè from participatin...  2024-04\n",
       "119                                        Interesting  2024-04"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\bookz\\AppData\\Local\\Temp\\ipykernel_9708\\3327462015.py:12: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
      "C:\\Users\\bookz\\AppData\\Local\\Temp\\ipykernel_9708\\3327462015.py:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  text = re.sub('\\w\\d\\w', '', text)\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "def clean(text):\n",
    "    import re\n",
    "    import nltk\n",
    "    from nltk.util import pr\n",
    "    stemmer = nltk.SnowballStemmer(\"english\")\n",
    "    from nltk.corpus import stopwords\n",
    "    import string\n",
    "    stopword = set(stopwords.words(\"english\"))\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('[.?]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w\\d\\w', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text = \" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "with open('../backend/textback/models/clean_function.pkl', 'wb') as f:\n",
    "     dill.dump(clean, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model = pickle.load(open(\"../backend/textback/models/model.pkl\",\"rb\"))\n",
    "cv = pickle.load(open(\"../backend/textback/models/vectorizer.pkl\",\"rb\"))\n",
    "\n",
    "def predict(input):\n",
    "    input = cv.transform([input]).toarray()\n",
    "    predict = model.predict(input)[0]\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score about Negative and Nuetral in This user is\n",
      " Negative =  18 \n",
      " Nuetral =  102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bookz\\AppData\\Local\\Temp\\ipykernel_9708\\3027145680.py:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['score'] = data['score'].replace({'No hate and offensive speech':0,'Offensive language detected':1,'Hate speech Detected':2})\n"
     ]
    }
   ],
   "source": [
    "tweets_cleaned = []\n",
    "Negative = 0\n",
    "Nuetral = 0\n",
    "for i in range(len(final_tweets)):\n",
    "    clean_tweets = clean(final_tweets[i])\n",
    "    if clean_tweets != \"\":\n",
    "        tweets_cleaned.append(clean_tweets)\n",
    "\n",
    "\n",
    "for i in range(len(tweets_cleaned)):\n",
    "    prediction = predict(tweets_cleaned[i])\n",
    "    if prediction == \"No hate and offensive speech\":\n",
    "        Nuetral += 1\n",
    "    elif prediction == \"Offensive language detected\":\n",
    "        Negative += 1\n",
    "    else :\n",
    "       Negative += 1\n",
    "\n",
    "#keep the score for each text in the dataframe file\n",
    "data['score'] = data['text'].apply(predict)\n",
    "\n",
    "#change score to numeric form 0,1,2\n",
    "data['score'] = data['score'].replace({'No hate and offensive speech':0,'Offensive language detected':1,'Hate speech Detected':2})\n",
    "print(\"Score about Negative and Nuetral in This user is\\n Negative = \" , Negative , \"\\n Nuetral = \" , Nuetral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data to csv file\n",
    "data['Month'] = data['date'].dt.month\n",
    "data.to_csv('gay.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
