{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ntscraper import Nitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [01:44<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "Scraper = Nitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29-Apr-24 02:42:58 - No instance specified, using random instance https://nitter.esmailelbob.xyz\n",
      "29-Apr-24 02:43:04 - Current stats for BarackObama: 20 tweets, 0 threads...\n"
     ]
    }
   ],
   "source": [
    "#tweets =Scraper.get_tweets(\"realDonaldTrump\",mode ='user',number = 100)\n",
    "def scraping(input):\n",
    "    tweets =Scraper.get_tweets(input,mode ='user',number = 500)\n",
    "    return tweets\n",
    "\n",
    "tweets = scraping(\"BarackObama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tweets = []\n",
    "for tweet in tweets['tweets']:\n",
    "    #data = [tweet['link'],tweet['text'],tweet['date'],tweet['stats']['likes'],tweet['stats']['comments']]\n",
    "    data = [tweet['text'],tweet['date']]\n",
    "    final_tweets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.DataFrame(final_tweets, columns= ['text','date'])\n",
    "#columns= ['link','text','date','no_likes','comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bookz\\AppData\\Local\\Temp\\ipykernel_9708\\4118179080.py:2: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  data['date'] = data['date'].dt.to_period('M')\n"
     ]
    }
   ],
   "source": [
    "data['date'] = pd.to_datetime(data['date'], format='%b %d, %Y ¬∑ %I:%M %p %Z')\n",
    "data['date'] = data['date'].dt.to_period('M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NPR has become a hard left propaganda machine ...</td>\n",
       "      <td>2024-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>FSD Supervised continues to improve with every...</td>\n",
       "      <td>2024-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Interesting series about a potentially good fu...</td>\n",
       "      <td>2024-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>United States laws prevent ùïè from participatin...</td>\n",
       "      <td>2024-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Interesting</td>\n",
       "      <td>2024-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text     date\n",
       "115  NPR has become a hard left propaganda machine ...  2024-04\n",
       "116  FSD Supervised continues to improve with every...  2024-04\n",
       "117  Interesting series about a potentially good fu...  2024-04\n",
       "118  United States laws prevent ùïè from participatin...  2024-04\n",
       "119                                        Interesting  2024-04"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\bookz\\AppData\\Local\\Temp\\ipykernel_8596\\1097536049.py:12: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
      "C:\\Users\\bookz\\AppData\\Local\\Temp\\ipykernel_8596\\1097536049.py:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  text = re.sub('\\w\\d\\w', '', text)\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "def clean(text):\n",
    "    import re\n",
    "    import nltk\n",
    "    from nltk.util import pr\n",
    "    stemmer = nltk.SnowballStemmer(\"english\")\n",
    "    from nltk.corpus import stopwords\n",
    "    import string\n",
    "    stopword = set(stopwords.words(\"english\"))\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('[.?]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w\\d\\w', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text = \" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "with open('../backend/textback/models/clean_function.pkl', 'wb') as f:\n",
    "     dill.dump(clean, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model = pickle.load(open(\"../backend/textback/models/model.pkl\",\"rb\"))\n",
    "cv = pickle.load(open(\"../backend/textback/models/vectorizer.pkl\",\"rb\"))\n",
    "\n",
    "def predict(input):\n",
    "    input = cv.transform([input]).toarray()\n",
    "    predict = model.predict(input)[0]\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score about Negative and Nuetral in This user is\n",
      " Negative =  18 \n",
      " Nuetral =  102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bookz\\AppData\\Local\\Temp\\ipykernel_9708\\3027145680.py:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['score'] = data['score'].replace({'No hate and offensive speech':0,'Offensive language detected':1,'Hate speech Detected':2})\n"
     ]
    }
   ],
   "source": [
    "tweets_cleaned = []\n",
    "Negative = 0\n",
    "Nuetral = 0\n",
    "for i in range(len(final_tweets)):\n",
    "    clean_tweets = clean(final_tweets[i])\n",
    "    if clean_tweets != \"\":\n",
    "        tweets_cleaned.append(clean_tweets)\n",
    "\n",
    "\n",
    "for i in range(len(tweets_cleaned)):\n",
    "    prediction = predict(tweets_cleaned[i])\n",
    "    if prediction == \"No hate and offensive speech\":\n",
    "        Nuetral += 1\n",
    "    elif prediction == \"Offensive language detected\":\n",
    "        Negative += 1\n",
    "    else :\n",
    "       Negative += 1\n",
    "\n",
    "#keep the score for each text in the dataframe file\n",
    "data['score'] = data['text'].apply(predict)\n",
    "\n",
    "#change score to numeric form 0,1,2\n",
    "data['score'] = data['score'].replace({'No hate and offensive speech':0,'Offensive language detected':1,'Hate speech Detected':2})\n",
    "print(\"Score about Negative and Nuetral in This user is\\n Negative = \" , Negative , \"\\n Nuetral = \" , Nuetral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data to csv file\n",
    "data['Month'] = data['date'].dt.month\n",
    "data.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
